{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd02136a9c3637fd160483224d7922e48bf03b650be5dff26724a0c1f8d1279953b",
   "display_name": "Python 3.8.8 64-bit ('NLP')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Using Sentida\n",
    "\n",
    "Simplest use case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentida\n",
    "polarity = sentida.PolarityModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'neg': 0.0, 'neu': 0.273, 'pos': 0.727, 'compound': 0.7456}\n{'neg': 0.0, 'neu': 0.348, 'pos': 0.652, 'compound': 0.7667}\n{'neg': 0.0, 'neu': 0.36, 'pos': 0.64, 'compound': 0.7456}\n{'neg': 0.0, 'neu': 0.248, 'pos': 0.752, 'compound': 0.7945}\n"
     ]
    }
   ],
   "source": [
    "print(polarity(\"jeg er glad\"))\n",
    "print(polarity(\"jeg er glad!\"))\n",
    "print(polarity(\"jeg er meget glad\")) # hmm this should be higher\n",
    "print(polarity(\"jeg er GLAD\")) # this should also be higher\n",
    "print(polarity(\"JEG ER GLAD\")) # should this also be higher?"
   ]
  },
  {
   "source": [
    "# Custom SpaCy pipeline\n",
    "To use a custom SpaCy pipeline you can simply do the following:\n",
    "\n",
    "This uses the Danish model `da_core_news_sm` to install it please run:\n",
    "\n",
    "```python\n",
    "python -m spacy download da_core_news_sm\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spay'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7641ac9e5cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# create a spacy doc extention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"polarity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentida\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spay'"
     ]
    }
   ],
   "source": [
    "from spay.tokens import Doc\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "\n",
    "# create a spacy doc extention\n",
    "Doc.set_extension(\"polarity\", getter=sentida.polarity_getter)\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "doc._.polarity"
   ]
  },
  {
   "source": [
    "# Custom Lemmatization\n",
    "\n",
    "You can use custom lemmatization in Sentida using the following:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (<ipython-input-4-dcaf028654c5>, line 3)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-dcaf028654c5>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    text = doc.texttokenlist=[t.lemma_ for t in doc])\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "import sentida\n",
    "\n",
    "lemmas=[t.lemma_ for t in doc] # using the spacy lemmas, but feel free to replace with your own\n",
    "\n",
    "analyzer = sentida.SentimentIntensityAnalyzer()\n",
    "polarity = analyser.polarity_scores(text, tokenlist=lemmas)"
   ]
  },
  {
   "source": [
    "# Custom Lexicons\n",
    "You can use a custom lexicon using the following:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_file=\"vader_lexicon_da.csv\"\n",
    "\n",
    "df = pd.read_csv(lexicon_full_filepath, encoding='ISO-8859-1')\n",
    "lexicon = df.set_index(\"stem\")[ 'score'].to_dict()\n",
    "\n",
    "analyzer = sentida.SentimentIntensityAnalyzer(lexicon=lexicon)"
   ]
  },
  {
   "source": [
    "## Custom Emoticon Lexicon\n",
    "Similarly for emoticon you can use a custom lexicon as so:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = analyzer.emoji_full_filepath = f.read()\n",
    "\n",
    "analyzer = sentida.SentimentIntensityAnalyzer(emoji_lexicon=emoji_dict)"
   ]
  }
 ]
}